---
title: "*de Novo* Assembly"
---

**_The de novo step is not necessary if a model genome or previous alignment is available (skip to Align individuals to loci)_**   

## Choosing Individuals
1. Pick your best 5 - 10 individuals (using `du -hs` or `wc -l`)

2. Copy these individuals (just RA) into a new directory

## Option 1 (Clean up reads in a single script)

1. Make an indiv file list (for however many files you chose). Start by making a list of files using sed:
    - `ls fastq | sed "s:.fastq::g" > list`
    
2. Modify and run the script `Hash_reads.sh`, which will run all three perl scripts (see Option 2)

## Option 2 (Clean up reads one script/Indiv at a time)

1. Modify file for quality control by throwing out seqs which do not meet threshold
    - Example `perl QualityFilter.pl Dpup_007_RA.fastq > Dpupt_oo7_RA_QF.fastq`
    - Do for all individuals you chose  
2. Find and shrink seqs to only unique ones while culling down file from 4 lines to 2 lines
    - `perl HashSeqs.pl Dpup_007_RA_QF.fastq Dpup_007 > Dpup_007_RA_QF.hash`
    - Do for all indivduals you chose
3. Depending on coverage, you can look at the distribution and see the # of occurrences vs. # of sequences, expect a peak a some point followed by a dip and a recovery, with a spike early on (usually errors).
    - `perl PrintHashHisto.pl Dpup_007_RA_QF.hash`
    - Do for all individuals you chose
4. May need more samples because don't have many sequences within the distribution (low coverage)

## Alignment

Before aligning, need to know parameters for alignment script. To count files in a dir:

```{bash, eval=F}
ls -l *.hash | wc -l
```

Concatenate all the hash files `cat *.hash > _.fasta` where the underscore can be anything you want (like a name)
  - Make sure **novoalign** (a program) is in your bin or PATH or copied to this directory

### Index
 
Create the novoindex index file (can run with 32G if need more memory):
  - `screen` See notes at start of this pipeline in case you are unfamiliar
  - `srun --mem=16G novoindex _.fa.idx _.fasta` This is what you want it called and whatever your fasta file was named
  - Use smap to view task `smap -c | grep your_user_name`

### Align

Now align index to itself, with following:  
  - `screen` See notes at start of this pipeline in case you are unfamiliar
  - `srun --mem=16G novoalign -r E 48 -t 180 -d _.fa.idx -f _.fasta > _.novo`
  - Output is a **"_.novo"_** file
  - Check size of file with `du -hs * | sort -hr`

## ID loci

 1. Now identify loci: 
    - `screen` See notes at start of this pipeline in case you are unfamiliar
    - `srun --mem=16G IdentifyLoci3.pl _.novo > _IDloci.fasta`

 2. Once done counting loci, divide by 2 to get idea of how many loci we are dealing with, perl can only handle 8000 lines and 4000 loci chunks (*We will need to split _IDloci.fasta into 8000 line chunks*)
    - See how many polymorphic loci exist
`perl SimplifyLoci2.pl _IDloci.fasta | grep "_2" | wc -l`

## Price (Extension)

 1. Now create PRICE directory and extendLoci directories inside PRICE  
    - `mkdir PRICE [in denovo folder]`
    - `mkdir extendLoci_1` (if 104,000 or less (aa:az)) *4000 loci x 26 letters (a-z) equals 104,000*
    - `mkdir extendLoci_2` (if >104,000 loci)           *add another directory for each 104000 you will need.* 
    - This is common when a six cutter is used because more loci will be generated.

 2. Make sure you have scripts required in the PRICE directory:  
    - `cp ~PATH/RecoverLocusSpecificReads.pl ./`  (*This must be in the PRICE directory*)
    - `getLoci.py`                              
    - `RecoverLocusSpecificReads.sh`
    - `extendLoci.sh`
    - `format_contigs.sh`
    - `cat.sh`
    - `select_loci.py` (*This must be in the PRICE directory*)

 3. Cat all your R1 & R2 files into one file each (one R1 and one R2) and copy to PRICE:  
   *Depending on the size and number of seq, may be best to sbatch*
    - `cat *_RA.fastq > RABO_R1.fastq` For example RABO is the species name and its all individuals sequenced
    - `cat *_RB.fastq > RABO_R2.fastq`
    - `cp RABO* ./PRICE`

 4. wc -l the ID Loci file and divide by 2 to see how many loci
    - `????? / 2 =` **?????? LOCI** using `IDLoci2`

 5. Strip names off of files to make a simplified version:
    - `perl ~/scripts/SimplifyLoci2.pl _IDloci.fasta | grep --no-group-separator -A 1 "_1" > _IDloci_s.fasta`
    - Then remove the _1 and make a `simplified final` version
    - `sed 's/_1//' _IDloci_s.fasta > _IDloci_sf.fasta`

 6. Split files into 8000 line chunks in the PRICE folder
    - `split -l 8000 _IDloci_sf.fasta _IDloci_sf.fasta'_'`  This should give you the same file name plus aa,ab,ac,etc at the end of the file name
    - Double check with tail and wc -l to make sure each chunk is 8000 (except last one)

 7. Make a list of all the output files you just made (e.g., `_IDloci_sf.fasta_aa`, `_IDloci_sf.fasta_ab`)
    - `ls *.fasta_a* > data_list`
 
 8. To get an idea of how many loci you have, open the last file created by splitting and 
`tail _IDloci_sf.fasta_a?` and the last number is the number of loci you have (R??????) OR
you can use the number of loci you found in #4 (good to check both really)

 9. In PRICE create a `Loci_aa` file which is a list of R000001 to whatever locus number you have from #8 (up to R104000) and (*if necessary*) a `Loci_bb` which is R104001 to whatever locus number you have. You can use the Rscript (`makelist.R`) or use a text editor.
    - Make a list of each line number (i.e., R000001 >> ?), use Rscript `makelist.R`
  `numbs<-seq(1:108279)` Again this is assuming you have 108279 loci
  `rabo<-sprintf("R%06d", numbs)`
  `write.table(rabo, quote=FALSE, col.names = FALSE, row.names = F)`
    - `Rscript makelist.R` Should provide Loci_aa and Loci_bb files

### Adjust Scripts

 1. Copy the following scripts into each `extendLoci_*` directory you created
    - `RecoverLocusSpecificReads.sh`
    - `extendLoci.sh`
    - `format_contigs.sh`
    - `cat.sh`
    - `getLoci.py` 
   
 2. VIM (or another text editor) `RecoverLocusSpecificReads.sh` to reflect your ../data_list and two fastq files (../_R1.fastq and ../_R2.fastq). Also adjust `$x -le ?` to reflect the number of files in your data_list (so if you have aa->ag, ? = 7). 
    - This builds shell scripts in the PRICE directory for each aa -> whatever that you have

 3. VIM `extendLoci.sh` and adjust as needed:
    - Change the number(?) in $x -le ? to whatever your total loci number is from #8 (*max 104000*) which covers the aa up to a? files in `extendLoci_1.sh`

 4. VIM `format_contigs.sh` and adjust as needed:
    - Change the number(?) in $x -le ? to whatever your total loci number is from #8 (*max 104000*) which covers the aa up to a? files in `format_contigs.sh`

**Run scripts in each extendLoci directory IN ORDER from within that directory:**

 5. Now run `RecoverLocusSpecificReads.sh` in `extend_Loci_?` directory
    - `sbatch RecoverLocusSpecificReads.sh with Loci list (data_list)`to create sh files in PRICE 

 6. Then run these from the extendLoci_* directories, one at a time, in order. 
    - `sbatch extendLoci.sh ../Loci_aa`
    - `sbatch format_contigs.sh ../Loci_aa`
    - `sbatch cat.sh aa`
    - Do the same for Loci_bb (which would be R104000->whatever) in extendLoci_2 **if necessary**
 
 7. To obtain the file you need (aa_contigs.fasta) which was output from cat.sh, and needs to be in PRICE, `mv aa_contigs.fasta ../`

<span style="color:red">_Be careful not to "ls" the `extendLoci_*` directories as they are very full and may stall your command line_</span> 

 8. Cat Loci_aa and Loci_bb together, if necessary: `cat Loci_??_contigs.fasta > final_contigs.fasta`

 9. Then select loci with 300 bp or more:  `python select_loci.py final_contigs.fasta 300`
    - word count to see total loci `wc -l final_contigs`
    - The number of total loci is **??????/2** #4 or #8 above
    - The number of total loci with minimum length 300 is **??????/2** #18
